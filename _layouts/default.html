<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ARMI Lab: Autonomous Robotics & Machine Intelligence</title>
    <!-- Load Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- Configure Tailwind for Inter font and a modern color palette -->
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@100..900&display=swap');

    /* ------------------------------
       COLOR SYSTEM
       ------------------------------ */
    :root {
    --primary: #0A1A2F;
    --secondary: #D12B2B;
    --text-dark: #000000;
    --text-light: #ffffff;
    --bg-light: #ffffff;
    --bg-dark: #0d1117;
    --card-dark: #111827;
}


    .dark {
        color-scheme: dark;
    }

    
    body {
        font-family: 'Inter', sans-serif;
        transition: background-color 0.3s, color 0.3s;
        background-color: var(--bg-light);
        color: var(--text-dark);
    }

    .dark body {
        background-color: var(--bg-dark);
        color: var(--text-light);
    }

    /* ------------------------------
       CARD CONTAINER
       ------------------------------ */
    .card-container {
        max-width: 1200px;
        margin: 0 auto;
        background-color: var(--bg-light);
        border-radius: 2rem;
        padding: 2.5rem;
        border: 2px solid var(--primary); /* subtle dark blue frame */
    }

    .dark .card-container {
        background-color: var(--card-dark);
        border-color: var(--secondary); /* red outline in dark mode */
    }

    /* ------------------------------
       PROJECT CARDS
       ------------------------------ */
    .project-card {
        display: flex;
        flex-direction: column;
        border-radius: 1rem;
        overflow: hidden;
        height: 100%;
        transition: all 0.3s ease;
        border: 1px solid rgba(10, 26, 47, 0.15); /* Dark blue tint */
    }

    .project-card:hover {
        transform: translateY(-6px);
        box-shadow: 0 12px 20px rgba(0, 0, 0, 0.15);
        border-color: var(--secondary); /* highlight with red */
    }

    /* ------------------------------
       LINK ICON
       ------------------------------ */
    .link-icon {
        @apply inline-block ml-2 transition;
        color: var(--primary);
    }
    .link-icon:hover {
        color: var(--secondary);
    }

    /* ------------------------------
       VIDEO WRAPPER
       ------------------------------ */
    .video-wrapper {
        position: relative;
        padding-bottom: 56.25%;
        height: 0;
        overflow: hidden;
        max-width: 100%;
        background: #000000; /* pure black for video frame */
        border: 2px solid var(--primary);
        border-radius: 1rem;
    }

    .video-wrapper video {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
    }
</style>

   <script>
tailwind.config = {
    darkMode: 'class',
    theme: {
        extend: {
            colors: {
                primary: '#0A1A2F',     // Dark Blue
                secondary: '#D12B2B',   // Red
                black: '#000000',
                gray: {
                    DEFAULT: '#6b7280',
                    50: '#f9fafb',
                    100: '#f3f4f6',
                    200: '#e5e7eb',
                    300: '#d1d5db',
                    400: '#9ca3af',
                    500: '#6b7280',
                    600: '#4b5563',
                    700: '#374151',
                    800: '#1f2937',
                    900: '#111827'
                }
            }
        }
    }
}
</script>

</head>

<body class="bg-gray-100 text-gray-800 dark:bg-gray-900 dark:text-gray-200 p-4 md:p-10">

    <div class="card-container shadow-2xl lg:p-12 transition duration-500">

        <!-- Header and Lab Identity -->
        <header class="mb-12 border-b-4 pb-8 border-primary dark:border-primary">
            <h1 class="text-6xl font-extrabold text-primary mb-2">
                ARMI Lab
            </h1>
            <p class="text-3xl font-light text-gray-600 dark:text-gray-400">
                <strong>A</strong>utonomous <strong>R</strong>obotics and <strong>M</strong>achine <strong>I</strong>ntelligence Laboratory
            </p>
            <p class="mt-4 text-xl leading-relaxed text-gray-700 dark:text-gray-300">
                <strong class="font-semibold text-secondary"> The ARMI Lab is a research and innovation center at Cluster3, Vietnamese German University (VGU), Vietnam. ARMI Lab dedicated to advancing autonomous robotics, digital twin technologies, and machine learning to solve complex, real-world industrial challenges. Our mission is to develop intelligent robotic systems that not only perceive and understand their environment, but also adapt, learn, and optimize their behavior autonomously in industrial context.
            </p>
        </header>

        <!-- Core Responsibilities (Adapted from original template section) -->
       <ul class="grid grid-cols-1 md:grid-cols-2 gap-x-10 gap-y-5 text-lg text-gray-700 dark:text-gray-300">

    <!-- System Design -->
    <li class="flex items-start">
        <span class="text-secondary mr-3 mt-1">&#x25AA;</span>
        <p>
            <strong class="text-primary">System Design:</strong>
            Architect robotics software systems using middleware like
            <span class="font-mono bg-gray-200 dark:bg-gray-700 px-2 py-1 rounded">ROS/ROS2</span>,
            integrated with simulation tools such as Gazebo, IsaacSim, and high-fidelity Digital Twin pipelines.
        </p>
    </li>

    <!-- Algorithm Development -->
    <li class="flex items-start">
        <span class="text-secondary mr-3 mt-1">&#x25AA;</span>
        <p>
            <strong class="text-primary">Algorithm Development:</strong>
            Develop and optimize algorithms for
            <strong>Imitation Learning</strong> (ACT, Diffusion),
            advanced <strong>motion planning</strong> (RRT, trajectory optimization),
            <strong>inverse kinematics</strong>,
            and <strong>AI-driven perception</strong> including SLAM and multimodal sensor fusion.
        </p>
    </li>

    <!-- Simulation & Digital Twin -->
    <li class="flex items-start">
        <span class="text-secondary mr-3 mt-1">&#x25AA;</span>
        <p>
            <strong class="text-primary">Simulation &amp; Digital Twin:</strong>
            Configure high-fidelity <strong>Digital Twin</strong> environments to validate robotic behaviors,
            system stability, control robustness, and full mission workflows from simulation to deployment.
        </p>
    </li>

    <!-- Integration -->
    <li class="flex items-start">
        <span class="text-secondary mr-3 mt-1">&#x25AA;</span>
        <p>
            <strong class="text-primary">Integration:</strong>
            Interface specialized hardware with industrial robots
            (UR, Fanuc, KUKA, Franka, ABB) and key components
            (LiDAR, depth cameras, actuators, embedded systems)
            via middleware such as ROS/ROS 2 and real-time communication bridges.
        </p>
    </li>

    <!-- Mobile Robotics -->
    <li class="flex items-start">
        <span class="text-secondary mr-3 mt-1">&#x25AA;</span>
        <p>
            <strong class="text-primary">Mobile Robotics:</strong>
            Develop autonomous navigation stacks, including mapping, localization,
            obstacle avoidance, and path planning for AMRs, AGVs, and outdoor UGV platforms.
            Integrate sensor suites such as LiDAR, GPS, IMU, and stereo/depth cameras
            to achieve robust autonomy in dynamic industrial environments.
        </p>
    </li>

    <!-- Machine Learning -->
    <li class="flex items-start">
        <span class="text-secondary mr-3 mt-1">&#x25AA;</span>
        <p>
            <strong class="text-primary">Machine Learning &amp; AI Models:</strong>
            Build and deploy machine learning models for predictive maintenance,
            anomaly detection, object recognition, pose estimation, and task automation.
            Utilize modern AI pipelines including deep learning, transformers,
            reinforcement learning, and foundation models tailored for robotics applications.
        </p>
    </li>

</ul>


        <!-- Research Experiences -->
        <!-- Research Experiences -->
<section id="research" class="mb-12">
    <h2 class="text-4xl font-bold mb-8 text-gray-800 dark:text-gray-100 border-l-4 border-secondary pl-4">
        Selected Research Publications
    </h2>

    <div class="grid grid-cols-1 lg:grid-cols-2 xl:grid-cols-3 gap-10">

        <!-- Digital Twin -->
        <article class="project-card bg-gray-50 dark:bg-gray-800 shadow-md">
            <a href="#" data-video-url="images/fulls/DT_Unity.mp4"
               class="video-trigger block overflow-hidden h-48 bg-gray-200 dark:bg-gray-700">
                <img src="images/thumbs/digitaltwin.png"
                     class="w-full h-full object-cover transition-all duration-300 hover:opacity-80">
            </a>

            <div class="p-6 flex-grow">
                <h3 class="text-xl font-bold text-primary mb-2">
                    ROS based Digital Twin Framework for Collaboration Robot
                </h3>
                <h6 class="text-sm font-semibold text-gray-500 dark:text-gray-400 mb-3">
                    Tri Bien Minh*, Phu Do, Hung Q. Nguyen, Khang H. V. Nguyen, Thao T.T Phan  
                    — Proceedings of the International Conference on Sustainable Energy Technologies
                </h6>
                <p class="text-sm text-gray-600 dark:text-gray-300 mb-3">
                    This paper presents a real-time machine health monitoring digital twin (DT) framework 
                    for robot machine-tending based on ISO 23247. The system integrates OPC UA and ROS 
                    for seamless communication between physical and cyber layers.
                </p>
                <p class="text-sm">
                    <a href="https://link.springer.com/chapter/10.1007/978-981-97-1868-9_74" class="link-icon">Springer Link</a> •
                    <a href="https://www.researchgate.net/publication/382224667_A_Digital_Twin_Implementation_Framework_for_a_Collaborative_Robot_Based_on_Iso_23247" class="link-icon">Preprint</a> •
                    <a href="https://github.com/TriKnight/unity_universal_robots" class="link-icon">Code</a>
                </p>
            </div>
        </article>

        <!-- PBVS Dual UR -->
        <article class="project-card bg-gray-50 dark:bg-gray-800 shadow-md">
            <a href="#" data-video-url="images/fulls/UR_dual.mp4"
               class="video-trigger block overflow-hidden h-48 bg-gray-200 dark:bg-gray-700">
                <img src="images/thumbs/PBVS_UR_play.png"
                     class="w-full h-full object-cover transition-all duration-300 hover:opacity-80">
            </a>

            <div class="p-6 flex-grow">
                <h3 class="text-xl font-bold text-primary mb-2">
                    Position-based Visual Servoing with Dual Manipulators
                </h3>
                <h6 class="text-sm font-semibold text-gray-500 dark:text-gray-400 mb-3">
                    Tri Bien Minh*
                </h6>
                <p class="text-sm text-gray-600 dark:text-gray-300 mb-3">
                    The PBVS system uses a Realsense D435 camera to track ARTag trajectories from a collaborative UR10e robot. 
                    Joint velocity control enables real-time trajectory tracking using visual feedback.
                </p>
                <p class="text-sm">
                    <a href="#" data-video-url="images/fulls/UR_dual.mp4" class="video-trigger link-icon">Video</a> •
                    <a href="images/fulls/PBVS-UR.pdf" class="link-icon">Preprint</a>
                </p>
            </div>
        </article>

        <!-- Reactive Motion Control -->
        <article class="project-card bg-gray-50 dark:bg-gray-800 shadow-md">
            <a href="#" data-video-url="images/fulls/Reactive_motion.mp4"
               class="video-trigger block overflow-hidden h-48 bg-gray-200 dark:bg-gray-700">
                <img src="images/thumbs/Thumb_Reactive.png"
                     class="w-full h-full object-cover transition-all duration-300 hover:opacity-80">
            </a>

            <div class="p-6 flex-grow">
                <h3 class="text-xl font-bold text-primary mb-2">
                    Optimisation Algorithm for Reactive Motion Control Manipulator
                </h3>
                <h6 class="text-sm font-semibold text-gray-500 dark:text-gray-400 mb-3">
                    Tri Bien Minh*
                </h6>
                <p class="text-sm text-gray-600 dark:text-gray-300 mb-3">
                    Designs a reactive optimization-based controller that avoids static and dynamic obstacles 
                    while driving the robot toward a target pose.
                </p>
                <p class="text-sm">
                    <a href="#" data-video-url="images/fulls/Reactive_motion.mp4" class="video-trigger link-icon">Video</a>
                </p>
            </div>
        </article>

        <!-- LiDAR DBSCAN -->
        <article class="project-card bg-gray-50 dark:bg-gray-800 shadow-md">
            <a href="#" data-video-url="images/fulls/3DLidar.mp4"
               class="video-trigger block overflow-hidden h-48 bg-gray-200 dark:bg-gray-700">
                <img src="images/thumbs/Lidar_play.png"
                     class="w-full h-full object-cover transition-all duration-300 hover:opacity-80">
            </a>

            <div class="p-6 flex-grow">
                <h3 class="text-xl font-bold text-primary mb-2">
                    LiDAR-based Vehicle Detection using DBSCAN
                </h3>
                <h6 class="text-sm font-semibold text-gray-500 dark:text-gray-400 mb-3">
                    Tri Bien Minh*, Hien Vo Bich — ICCRI 2023
                </h6>
                <p class="text-sm text-gray-600 dark:text-gray-300 mb-3">
                    A LiDAR-based embedded detection system using DBSCAN clustering on Jetson TX2 
                    for real-time object detection in road environments.
                </p>
                <p class="text-sm">
                    <a href="#" data-video-url="images/fulls/3DLidar.mp4" class="video-trigger link-icon">Video</a> •
                    <a href="images/fulls/Tri_2023_PrePrint.pdf" class="link-icon">Preprint</a>
                </p>
            </div>
        </article>

        <!-- Robot Gesture Control -->
        <article class="project-card bg-gray-50 dark:bg-gray-800 shadow-md">
            <a href="#" data-video-url="images/fulls/Robot_Gesture_Control.mp4"
               class="video-trigger block overflow-hidden h-48 bg-gray-200 dark:bg-gray-700">
                <img src="images/thumbs/Robot_gesture_play.png"
                     class="w-full h-full object-cover transition-all duration-300 hover:opacity-80">
            </a>

            <div class="p-6 flex-grow">
                <h3 class="text-xl font-bold text-primary mb-2">
                    Robot Gesture Control Using Multi-Tracking System
                </h3>
                <h6 class="text-sm font-semibold text-gray-500 dark:text-gray-400 mb-3">
                    Khang Hoang Vinh Nguyen, Tri Bien Minh, Van Chi Le, Phu Xuan Do — AETA 2022
                </h6>
                <p class="text-sm text-gray-600 dark:text-gray-300 mb-3">
                    A wireless gesture-controlled robot system using Vicon motion capture for real-time control
                    without onboard computing or wearable electronics.
                </p>
                <p class="text-sm">
                    <a href="#" data-video-url="images/fulls/Robot_Gesture_Control.mp4" class="video-trigger link-icon">Video</a> •
                    <a href="images/fulls/Robot Gesture Control Using Online Feedback Data with Multi-Tracking Capture System.pdf" class="link-icon">Preprint</a>
                </p>
            </div>
        </article>

        <!-- MiniRos UGV -->
        <article class="project-card bg-gray-50 dark:bg-gray-800 shadow-md">
            <a href="https://www.youtube.com/watch?v=ZCQJhtsWnWg" target="_blank"
               class="block overflow-hidden h-48 bg-gray-200 dark:bg-gray-700">
                <img src="images/fulls/miniros.gif"
                     class="w-full h-full object-cover transition-all duration-300 hover:opacity-80">
            </a>

            <div class="p-6 flex-grow">
                <h3 class="text-xl font-bold text-primary mb-2">MiniRos: an autonomous UGV robot</h3>
                <h6 class="text-sm font-semibold text-gray-500 dark:text-gray-400 mb-3">
                    Tri Bien Minh*, Hua Thanh Luan, Do Xuan Phu — ICSSE 2021
                </h6>
                <p class="text-sm text-gray-600 dark:text-gray-300 mb-3">
                    A ROS-based autonomous mobile robot for education and research with 2D SLAM, navigation, and outdoor capabilities.
                </p>
            </div>
        </article>

        <!-- Octocopter -->
        <article class="project-card bg-gray-50 dark:bg-gray-800 shadow-md">
            <a href="images/fulls/Octocopter-Testbed.png"
               class="block overflow-hidden h-48 bg-gray-200 dark:bg-gray-700">
                <img src="images/thumbs/octocopter.png"
                     class="w-full h-full object-cover transition-all duration-300 hover:opacity-80">
            </a>

            <div class="p-6 flex-grow">
                <h3 class="text-xl font-bold text-primary mb-2">V-frame Octocopter: Design & Simulation</h3>
                <h6 class="text-sm font-semibold text-gray-500 dark:text-gray-400 mb-3">
                    Tri Bien Minh*, Hien Vo, Hua Thanh Luan — IJ Intelligent Unmanned Systems, 2023
                </h6>
                <p class="text-sm text-gray-600 dark:text-gray-300 mb-3">
                    A novel V-frame octocopter with FEM validation and Simulink PID tuning using Ziegler-Nichols method.
                </p>
            </div>
        </article>

        <!-- Exoskeleton Control -->
        <article class="project-card bg-gray-50 dark:bg-gray-800 shadow-md">
            <a href="images/fulls/Upper_robot.png"
               class="block overflow-hidden h-48 bg-gray-200 dark:bg-gray-700">
                <img src="images/thumbs/Upper_robot.png"
                     class="w-full h-full object-cover transition-all duration-300 hover:opacity-80">
            </a>

            <div class="p-6 flex-grow">
                <h3 class="text-xl font-bold text-primary mb-2">
                    Adaptive Optimal Control for Upper Exoskeleton
                </h3>
                <h6 class="text-sm font-semibold text-gray-500 dark:text-gray-400 mb-3">
                    Do Xuan Phu, Tri Bien Minh — ICMT 2021
                </h6>
                <p class="text-sm text-gray-600 dark:text-gray-300">
                    A novel saturation-function-based optimal controller for upper-extremity exoskeletons, validated in simulation.
                </p>
            </div>
        </article>

    </div>
</section>




        <!-- Robotics Projects -->
       <!-- Robotics Projects -->
<section id="projects" class="mb-12">
    <h2 class="text-4xl font-bold mb-8 text-gray-800 dark:text-gray-100 border-l-4 border-secondary pl-4">
        Robotics Project Portfolio
    </h2>

    <div class="grid grid-cols-1 sm:grid-cols-2 lg:grid-cols-3 gap-8">

        <!-- Project 1: Upper body humanoid robot design -->
        <article class="project-card bg-gray-50 dark:bg-gray-800 shadow-md">
            <a href="images/fulls/Upper_full.JPG" class="block overflow-hidden h-48 bg-gray-200 dark:bg-gray-700">
                <img src="images/thumbs/Upper1.JPG"
                     alt="Upper body humanoid robot design"
                     class="w-full h-full object-cover">
            </a>
            <div class="p-6 flex-grow">
                <h3 class="text-xl font-bold mb-2 text-primary">Upper body humanoid robot design (14 DOF)</h3>
                <p class="text-sm text-gray-600 dark:text-gray-300">
                    14DOF humanoid upper body robot (6-DOF head + 2× 4-DOF arms), integrated with a depth camera. Designed for 3D printing or laser cutting — for research & education.
                </p>
            </div>
            <div class="p-6 pt-0 border-t border-gray-200 dark:border-gray-700">
                <a href="https://grabcad.com/library/upper-body-humanoid-robot-1" class="link-icon">3D File (GrabCAD)</a>
            </div>
        </article>

        <!-- Project 2: Autonomous Service Robot -->
        <article class="project-card bg-gray-50 dark:bg-gray-800 shadow-md">
            <a href="https://youtu.be/kqwAIAZnEu0" target="_blank"
               class="block overflow-hidden h-48 bg-gray-200 dark:bg-gray-700 cursor-pointer">
                <img src="images/thumbs/Saviman_thumb.jpg"
                     alt="Autonomous Service Robot"
                     class="w-full h-full object-cover">
            </a>
            <div class="p-6 flex-grow">
                <h3 class="text-xl font-bold mb-2 text-primary">Autonomous Service Robot</h3>
                <p class="text-sm text-gray-600 dark:text-gray-300">
                    ROS-based service robot using 2D Lidar, embedded computer, and multiple sensors. Supports indoor SLAM and autonomous navigation for restaurants, hotels, and hospitals.
                </p>
            </div>
            <div class="p-6 pt-0 border-t border-gray-200 dark:border-gray-700">
                <a href="https://youtu.be/kqwAIAZnEu0" class="link-icon">Video</a>
            </div>
        </article>

        <!-- Project 3: Docking and Locking for Electric Bike -->
        <article class="project-card bg-gray-50 dark:bg-gray-800 shadow-md">
            <a href="images/thumbs/Bosch_Docking_Locking_White_3.JPG"
               class="block overflow-hidden h-48 bg-gray-200 dark:bg-gray-700">
                <img src="images/thumbs/Bosch_Docking_Locking_White_3.JPG"
                     alt="Docking and Locking System"
                     class="w-full h-full object-cover">
            </a>
            <div class="p-6 flex-grow">
                <h3 class="text-xl font-bold mb-2 text-primary">Docking & Locking for Electric Bike</h3>
                <p class="text-sm text-gray-600 dark:text-gray-300">
                    Award-winning charger docking and locking system for electric motorbikes — developed for the Bosch Green Challenge. Recognized for innovation in industrial design.
                </p>
            </div>
            <div class="p-6 pt-0 border-t border-gray-200 dark:border-gray-700">
                <a href="https://grabcad.com/library/docking-and-locking-pole-for-electric-bike-1"
                   class="link-icon">3D File (GrabCAD)</a>
            </div>
        </article>

        <!-- Project 4: Ant-like robot -->
        <article class="project-card bg-gray-50 dark:bg-gray-800 shadow-md">
            <a href="images/fulls/Ant_full.JPG"
               class="block overflow-hidden h-48 bg-gray-200 dark:bg-gray-700">
                <img src="images/thumbs/Nice_Ant_robot.jpg"
                     alt="Ant-like robot"
                     class="w-full h-full object-cover">
            </a>
            <div class="p-6 flex-grow">
                <h3 class="text-xl font-bold mb-2 text-primary">Ant-like Robot (23 DOF)</h3>
                <p class="text-sm text-gray-600 dark:text-gray-300">
                    A six-legged, 23-DOF biomimetic robot with 3 DOF per leg. Uses servo motors and a lightweight frame — ideal for STEM education and locomotion research.
                </p>
            </div>
            <div class="p-6 pt-0 border-t border-gray-200 dark:border-gray-700">
                <a href="https://grabcad.com/library/ant-like-robot-1" class="link-icon">3D File (GrabCAD)</a>
            </div>
        </article>

        <!-- Project 5: 19-DOF RC Humanoid -->
        <article class="project-card bg-gray-50 dark:bg-gray-800 shadow-md">
            <a href="https://youtu.be/RDtGJLPC5hI" target="_blank"
               class="block overflow-hidden h-48 bg-gray-200 dark:bg-gray-700 cursor-pointer">
                <img src="images/thumbs/Humanoid0.JPG"
                     alt="RC Humanoid Robot 19 DOF"
                     class="w-full h-full object-cover">
            </a>
            <div class="p-6 flex-grow">
                <h3 class="text-xl font-bold mb-2 text-primary">RC Humanoid Robot (19 DOF)</h3>
                <p class="text-sm text-gray-600 dark:text-gray-300">
                    A remote-controlled 19-DOF humanoid built for mechanical engineering and robotics education. Designed to be easy to manufacture via 3D printing or laser cutting.
                </p>
            </div>
            <div class="p-6 pt-0 border-t border-gray-200 dark:border-gray-700">
                <a href="https://grabcad.com/library/humanoid-rc-robot-1" class="link-icon">3D File (GrabCAD)</a>
                <a href="https://youtu.be/RDtGJLPC5hI" class="link-icon">Video</a>
            </div>
        </article>

    </div>
</section>


        <!-- Technical Capabilities -->
        <section id="capabilities" class="mb-12 p-8 bg-gray-50 dark:bg-gray-800 rounded-2xl shadow-inner">
    <h2 class="text-4xl font-bold mb-6 text-gray-800 dark:text-gray-100 border-l-4 border-secondary pl-4">
        Technical Capabilities
    </h2>

    <div class="grid grid-cols-1 md:grid-cols-3 gap-8">
        
        <!-- Programming Skills -->
        <div>
            <h3 class="text-2xl font-semibold mb-3 text-primary">Programming & Frameworks</h3>
            <p class="text-lg text-gray-700 dark:text-gray-300 mb-4">
                Core development in low-level and high-level languages for robotics and AI.
            </p>
            <p align="left">
                <img src="https://skillicons.dev/icons?i=python,cpp,ros,pytorch,git,latex"
                     alt="Skills: Python, C++, ROS, PyTorch, Git, LaTeX"
                     class="w-full h-auto"/>
            </p>
        </div>
        
        <!-- Lab Tutorials / Teaching -->
        <div>
            <h3 class="text-2xl font-semibold mb-3 text-primary">Lab Tutorials & Curriculum</h3>
            <ul class="space-y-2 text-base text-gray-700 dark:text-gray-300 list-disc pl-5">
                <li>Robotics and Autonomous Systems (ROS, Pytorch)</li>
                <li>Embedded Intelligent System (ROS, OpenCV)</li>
                <li>Microcontroller / Digital Signal Processing</li>
                <li>Robotics Workshop (CAD and PCB Design)</li>
            </ul>   
        </div>
        
        <!-- Hands-on Hardware Experience -->
        <div>
            <h3 class="text-2xl font-semibold mb-3 text-primary">Hands-on Hardware Experience</h3>
            <ul class="space-y-2 text-base text-gray-700 dark:text-gray-300 list-disc pl-5">
                <li>Robot Platforms: UR10e, Kuka Youbot, Turtlebot 3, NAO, DJI Drone.</li>
                <li>Sensors: Velodyne VLP-16, IMU-Xsens Mti-30, Intel Realsense, SICK Lidar.</li>
                <li>Embedded Computers: Nvidia Jetson family, Raspberry Pi, NUC, Arduino.</li>
                <li>Actuators: Servo motors, linear actuators, motor drivers.</li>
            </ul>
        </div>
        
    </div>
    
    <!-- PCB Design Showcase -->
    <div class="mt-10">
        <h3 class="text-2xl font-semibold mb-3 text-primary">PCB Design Showcase</h3>
        <a href="images/fulls/PCB_Design.pdf"
           class="block overflow-hidden rounded-xl shadow-lg hover:shadow-xl transition duration-300">
            <img src="https://placehold.co/1200x250/4f46e5/ffffff?text=Example+PCB+Design+Schematic"
                 alt="PCB Design Example"
                 class="w-full h-auto object-cover">
        </a>
    </div>

</section>



    </div>
   
    <!-- ==================== VIDEO MODAL (SINGLE, FINAL) ===================== -->
<!-- Video Modal -->
<div id="video-modal"
    class="fixed inset-0 bg-black bg-opacity-80 flex items-center justify-center p-4 hidden z-50">

    <div class="w-full max-w-4xl bg-black rounded-xl overflow-hidden relative"
        onclick="event.stopPropagation()">

        <button onclick="closeVideoModal()"
            class="absolute top-3 right-3 text-white text-3xl hover:text-red-500">&times;</button>

        <div class="video-wrapper">
            <video id="video-player" controls playsinline></video>
        </div>

    </div>
</div>


    <!-- ====================== AUTOPLAY MODAL SCRIPT ========================= -->
    <script>
const modal = document.getElementById("video-modal");
const player = document.getElementById("video-player");

// Open modal + autoplay
function openVideoModal(url) {
    player.src = url;
    modal.classList.remove("hidden");

    setTimeout(() => {
        player.play().catch(err => console.log("Autoplay blocked:", err));
    }, 100);
}

// Close modal + stop video
function closeVideoModal() {
    modal.classList.add("hidden");
    player.pause();
    player.currentTime = 0;
    player.removeAttribute("src");
}

// Close when clicking background
modal.addEventListener("click", closeVideoModal);

// Detect clicks on articles
document.querySelectorAll(".video-trigger").forEach(el => {
    el.addEventListener("click", e => {
        e.preventDefault();
        openVideoModal(el.dataset.videoUrl);
    });
});
</script>


    <!-- Theme Toggle -->
    <button onclick="document.documentElement.classList.toggle('dark')"
        class="fixed bottom-4 right-4 bg-primary text-white p-3 rounded-full shadow-lg hover:bg-secondary transition">
        Toggle Theme
    </button>

</body>

</html>